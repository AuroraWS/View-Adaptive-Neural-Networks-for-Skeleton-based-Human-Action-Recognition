{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1adHEuzLEMjZbFBTAEjpxqeFkOg5XlcKX",
      "authorship_tag": "ABX9TyPVW0P7EoJe8Cy0h6aMfmM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AuroraWS/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition/blob/master/statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF_VZS9lmUDm",
        "outputId": "be07c238-e363-4433-8f5c-f9ee66f3e75a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (113945, 300, 150)\n",
            "-----------------------\n",
            "(38122, 300, 150)\n",
            "testing set sample before speed variation: \n",
            "NTU_CV.h5 is opened.\n",
            "check the first speed up sample in txt\n",
            "batch0-100 speedup and saved\n",
            "batch100-200 speedup and saved\n",
            "batch200-300 speedup and saved\n",
            "batch300-400 speedup and saved\n",
            "batch400-500 speedup and saved\n",
            "batch500-600 speedup and saved\n",
            "batch600-700 speedup and saved\n",
            "batch700-800 speedup and saved\n",
            "batch800-900 speedup and saved\n",
            "batch900-1000 speedup and saved\n",
            "batch1000-1100 speedup and saved\n",
            "batch1100-1200 speedup and saved\n",
            "batch1200-1300 speedup and saved\n",
            "batch1300-1400 speedup and saved\n",
            "batch1400-1500 speedup and saved\n",
            "batch1500-1600 speedup and saved\n",
            "batch1600-1700 speedup and saved\n",
            "batch1700-1800 speedup and saved\n",
            "batch1800-1900 speedup and saved\n",
            "batch1900-2000 speedup and saved\n",
            "batch2000-2100 speedup and saved\n",
            "batch2100-2200 speedup and saved\n",
            "batch2200-2300 speedup and saved\n",
            "batch2300-2400 speedup and saved\n",
            "batch2400-2500 speedup and saved\n",
            "batch2500-2600 speedup and saved\n",
            "batch2600-2700 speedup and saved\n",
            "batch2700-2800 speedup and saved\n",
            "batch2800-2900 speedup and saved\n",
            "batch2900-3000 speedup and saved\n",
            "batch3000-3100 speedup and saved\n",
            "batch3100-3200 speedup and saved\n",
            "batch3200-3300 speedup and saved\n",
            "batch3300-3400 speedup and saved\n",
            "batch3400-3500 speedup and saved\n",
            "batch3500-3600 speedup and saved\n",
            "batch3600-3700 speedup and saved\n",
            "batch3700-3800 speedup and saved\n",
            "batch3800-3900 speedup and saved\n",
            "batch3900-4000 speedup and saved\n",
            "batch4000-4100 speedup and saved\n",
            "batch4100-4200 speedup and saved\n",
            "batch4200-4300 speedup and saved\n",
            "batch4300-4400 speedup and saved\n",
            "batch4400-4500 speedup and saved\n",
            "batch4500-4600 speedup and saved\n",
            "batch4600-4700 speedup and saved\n",
            "batch4700-4800 speedup and saved\n",
            "batch4800-4900 speedup and saved\n",
            "batch4900-5000 speedup and saved\n",
            "batch5000-5100 speedup and saved\n",
            "batch5100-5200 speedup and saved\n",
            "batch5200-5300 speedup and saved\n",
            "batch5300-5400 speedup and saved\n",
            "batch5400-5500 speedup and saved\n",
            "batch5500-5600 speedup and saved\n",
            "batch5600-5700 speedup and saved\n",
            "batch5700-5800 speedup and saved\n",
            "batch5800-5900 speedup and saved\n",
            "batch5900-6000 speedup and saved\n",
            "batch6000-6100 speedup and saved\n",
            "batch6100-6200 speedup and saved\n",
            "batch6200-6300 speedup and saved\n",
            "batch6300-6400 speedup and saved\n",
            "batch6400-6500 speedup and saved\n",
            "batch6500-6600 speedup and saved\n",
            "batch6600-6700 speedup and saved\n",
            "batch6700-6800 speedup and saved\n",
            "batch6800-6900 speedup and saved\n",
            "batch6900-7000 speedup and saved\n",
            "batch7000-7100 speedup and saved\n",
            "batch7100-7200 speedup and saved\n",
            "batch7200-7300 speedup and saved\n",
            "batch7300-7400 speedup and saved\n",
            "batch7400-7500 speedup and saved\n",
            "batch7500-7600 speedup and saved\n",
            "batch7600-7700 speedup and saved\n",
            "batch7700-7800 speedup and saved\n",
            "batch7800-7900 speedup and saved\n",
            "batch7900-8000 speedup and saved\n",
            "batch8000-8100 speedup and saved\n",
            "batch8100-8200 speedup and saved\n",
            "batch8200-8300 speedup and saved\n",
            "batch8300-8400 speedup and saved\n",
            "batch8400-8500 speedup and saved\n",
            "batch8500-8600 speedup and saved\n",
            "batch8600-8700 speedup and saved\n",
            "batch8700-8800 speedup and saved\n",
            "batch8800-8900 speedup and saved\n",
            "batch8900-9000 speedup and saved\n",
            "batch9000-9100 speedup and saved\n",
            "batch9100-9200 speedup and saved\n",
            "batch9200-9300 speedup and saved\n",
            "batch9300-9400 speedup and saved\n",
            "batch9400-9500 speedup and saved\n",
            "batch9500-9600 speedup and saved\n",
            "batch9600-9700 speedup and saved\n",
            "batch9700-9800 speedup and saved\n",
            "batch9800-9900 speedup and saved\n",
            "batch9900-10000 speedup and saved\n",
            "batch10000-10100 speedup and saved\n",
            "batch10100-10200 speedup and saved\n",
            "batch10200-10300 speedup and saved\n",
            "batch10300-10400 speedup and saved\n",
            "batch10400-10500 speedup and saved\n",
            "batch10500-10600 speedup and saved\n",
            "batch10600-10700 speedup and saved\n",
            "batch10700-10800 speedup and saved\n",
            "batch10800-10900 speedup and saved\n",
            "batch10900-11000 speedup and saved\n",
            "batch11000-11100 speedup and saved\n",
            "batch11100-11200 speedup and saved\n",
            "batch11200-11300 speedup and saved\n",
            "batch11300-11400 speedup and saved\n",
            "batch11400-11500 speedup and saved\n",
            "batch11500-11600 speedup and saved\n",
            "batch11600-11700 speedup and saved\n",
            "batch11700-11800 speedup and saved\n",
            "batch11800-11900 speedup and saved\n",
            "batch11900-12000 speedup and saved\n",
            "batch12000-12100 speedup and saved\n",
            "batch12100-12200 speedup and saved\n",
            "batch12200-12300 speedup and saved\n",
            "batch12300-12400 speedup and saved\n",
            "batch12400-12500 speedup and saved\n",
            "batch12500-12600 speedup and saved\n",
            "batch12600-12700 speedup and saved\n",
            "batch12700-12800 speedup and saved\n",
            "batch12800-12900 speedup and saved\n",
            "batch12900-13000 speedup and saved\n",
            "batch13000-13100 speedup and saved\n",
            "batch13100-13200 speedup and saved\n",
            "batch13200-13300 speedup and saved\n",
            "batch13300-13400 speedup and saved\n",
            "batch13400-13500 speedup and saved\n",
            "batch13500-13600 speedup and saved\n",
            "batch13600-13700 speedup and saved\n",
            "batch13700-13800 speedup and saved\n",
            "batch13800-13900 speedup and saved\n",
            "batch13900-14000 speedup and saved\n",
            "batch14000-14100 speedup and saved\n",
            "batch14100-14200 speedup and saved\n",
            "batch14200-14300 speedup and saved\n",
            "batch14300-14400 speedup and saved\n",
            "batch14400-14500 speedup and saved\n",
            "batch14500-14600 speedup and saved\n",
            "batch14600-14700 speedup and saved\n",
            "batch14700-14800 speedup and saved\n",
            "batch14800-14900 speedup and saved\n",
            "batch14900-15000 speedup and saved\n",
            "batch15000-15100 speedup and saved\n",
            "batch15100-15200 speedup and saved\n",
            "batch15200-15300 speedup and saved\n",
            "batch15300-15400 speedup and saved\n",
            "batch15400-15500 speedup and saved\n",
            "batch15500-15600 speedup and saved\n",
            "batch15600-15700 speedup and saved\n",
            "batch15700-15800 speedup and saved\n",
            "batch15800-15900 speedup and saved\n",
            "batch15900-16000 speedup and saved\n",
            "batch16000-16100 speedup and saved\n",
            "batch16100-16200 speedup and saved\n",
            "batch16200-16300 speedup and saved\n",
            "batch16300-16400 speedup and saved\n",
            "batch16400-16500 speedup and saved\n",
            "batch16500-16600 speedup and saved\n",
            "batch16600-16700 speedup and saved\n",
            "batch16700-16800 speedup and saved\n",
            "batch16800-16900 speedup and saved\n",
            "batch16900-17000 speedup and saved\n",
            "batch17000-17100 speedup and saved\n",
            "batch17100-17200 speedup and saved\n",
            "batch17200-17300 speedup and saved\n",
            "batch17300-17400 speedup and saved\n",
            "batch17400-17500 speedup and saved\n",
            "batch17500-17600 speedup and saved\n",
            "batch17600-17700 speedup and saved\n",
            "batch17700-17800 speedup and saved\n",
            "batch17800-17900 speedup and saved\n",
            "batch17900-18000 speedup and saved\n",
            "batch18000-18100 speedup and saved\n",
            "batch18100-18200 speedup and saved\n",
            "batch18200-18300 speedup and saved\n",
            "batch18300-18400 speedup and saved\n",
            "batch18400-18500 speedup and saved\n",
            "batch18500-18600 speedup and saved\n",
            "batch18600-18700 speedup and saved\n",
            "batch18700-18800 speedup and saved\n",
            "batch18800-18900 speedup and saved\n",
            "batch18900-19000 speedup and saved\n",
            "batch19000-19100 speedup and saved\n",
            "batch19100-19200 speedup and saved\n",
            "batch19200-19300 speedup and saved\n",
            "batch19300-19400 speedup and saved\n",
            "batch19400-19500 speedup and saved\n",
            "batch19500-19600 speedup and saved\n",
            "batch19600-19700 speedup and saved\n",
            "batch19700-19800 speedup and saved\n",
            "batch19800-19900 speedup and saved\n",
            "batch19900-20000 speedup and saved\n",
            "batch20000-20100 speedup and saved\n",
            "batch20100-20200 speedup and saved\n",
            "batch20200-20300 speedup and saved\n",
            "batch20300-20400 speedup and saved\n",
            "batch20400-20500 speedup and saved\n",
            "batch20500-20600 speedup and saved\n",
            "batch20600-20700 speedup and saved\n",
            "batch20700-20800 speedup and saved\n",
            "batch20800-20900 speedup and saved\n",
            "batch20900-21000 speedup and saved\n",
            "batch21000-21100 speedup and saved\n",
            "batch21100-21200 speedup and saved\n",
            "batch21200-21300 speedup and saved\n",
            "batch21300-21400 speedup and saved\n",
            "batch21400-21500 speedup and saved\n",
            "batch21500-21600 speedup and saved\n",
            "batch21600-21700 speedup and saved\n",
            "batch21700-21800 speedup and saved\n",
            "batch21800-21900 speedup and saved\n",
            "batch21900-22000 speedup and saved\n",
            "batch22000-22100 speedup and saved\n",
            "batch22100-22200 speedup and saved\n",
            "batch22200-22300 speedup and saved\n",
            "batch22300-22400 speedup and saved\n",
            "batch22400-22500 speedup and saved\n",
            "batch22500-22600 speedup and saved\n",
            "batch22600-22700 speedup and saved\n",
            "batch22700-22800 speedup and saved\n",
            "batch22800-22900 speedup and saved\n",
            "batch22900-23000 speedup and saved\n",
            "batch23000-23100 speedup and saved\n",
            "batch23100-23200 speedup and saved\n",
            "batch23200-23300 speedup and saved\n",
            "batch23300-23400 speedup and saved\n",
            "batch23400-23500 speedup and saved\n",
            "batch23500-23600 speedup and saved\n",
            "batch23600-23700 speedup and saved\n",
            "batch23700-23800 speedup and saved\n",
            "batch23800-23900 speedup and saved\n",
            "batch23900-24000 speedup and saved\n",
            "batch24000-24100 speedup and saved\n",
            "batch24100-24200 speedup and saved\n",
            "batch24200-24300 speedup and saved\n",
            "batch24300-24400 speedup and saved\n",
            "batch24400-24500 speedup and saved\n",
            "batch24500-24600 speedup and saved\n",
            "batch24600-24700 speedup and saved\n",
            "batch24700-24800 speedup and saved\n",
            "batch24800-24900 speedup and saved\n",
            "batch24900-25000 speedup and saved\n",
            "batch25000-25100 speedup and saved\n",
            "batch25100-25200 speedup and saved\n",
            "batch25200-25300 speedup and saved\n",
            "batch25300-25400 speedup and saved\n",
            "batch25400-25500 speedup and saved\n",
            "batch25500-25600 speedup and saved\n",
            "batch25600-25700 speedup and saved\n",
            "batch25700-25800 speedup and saved\n",
            "batch25800-25900 speedup and saved\n",
            "batch25900-26000 speedup and saved\n",
            "batch26000-26100 speedup and saved\n",
            "batch26100-26200 speedup and saved\n",
            "batch26200-26300 speedup and saved\n",
            "batch26300-26400 speedup and saved\n",
            "batch26400-26500 speedup and saved\n",
            "batch26500-26600 speedup and saved\n",
            "batch26600-26700 speedup and saved\n",
            "batch26700-26800 speedup and saved\n",
            "batch26800-26900 speedup and saved\n",
            "batch26900-27000 speedup and saved\n",
            "batch27000-27100 speedup and saved\n",
            "batch27100-27200 speedup and saved\n",
            "batch27200-27300 speedup and saved\n",
            "batch27300-27400 speedup and saved\n",
            "batch27400-27500 speedup and saved\n",
            "batch27500-27600 speedup and saved\n",
            "batch27600-27700 speedup and saved\n",
            "batch27700-27800 speedup and saved\n",
            "batch27800-27900 speedup and saved\n",
            "batch27900-28000 speedup and saved\n",
            "batch28000-28100 speedup and saved\n",
            "batch28100-28200 speedup and saved\n",
            "batch28200-28300 speedup and saved\n",
            "batch28300-28400 speedup and saved\n",
            "batch28400-28500 speedup and saved\n",
            "batch28500-28600 speedup and saved\n",
            "batch28600-28700 speedup and saved\n",
            "batch28700-28800 speedup and saved\n",
            "batch28800-28900 speedup and saved\n",
            "batch28900-29000 speedup and saved\n",
            "batch29000-29100 speedup and saved\n",
            "batch29100-29200 speedup and saved\n",
            "batch29200-29300 speedup and saved\n",
            "batch29300-29400 speedup and saved\n",
            "batch29400-29500 speedup and saved\n",
            "batch29500-29600 speedup and saved\n",
            "batch29600-29700 speedup and saved\n",
            "batch29700-29800 speedup and saved\n",
            "batch29800-29900 speedup and saved\n",
            "batch29900-30000 speedup and saved\n",
            "batch30000-30100 speedup and saved\n",
            "batch30100-30200 speedup and saved\n",
            "batch30200-30300 speedup and saved\n",
            "batch30300-30400 speedup and saved\n",
            "batch30400-30500 speedup and saved\n",
            "batch30500-30600 speedup and saved\n",
            "batch30600-30700 speedup and saved\n",
            "batch30700-30800 speedup and saved\n",
            "batch30800-30900 speedup and saved\n",
            "batch30900-31000 speedup and saved\n",
            "batch31000-31100 speedup and saved\n",
            "batch31100-31200 speedup and saved\n",
            "batch31200-31300 speedup and saved\n",
            "batch31300-31400 speedup and saved\n",
            "batch31400-31500 speedup and saved\n",
            "batch31500-31600 speedup and saved\n",
            "batch31600-31700 speedup and saved\n",
            "batch31700-31800 speedup and saved\n",
            "batch31800-31900 speedup and saved\n",
            "batch31900-32000 speedup and saved\n",
            "batch32000-32100 speedup and saved\n",
            "batch32100-32200 speedup and saved\n",
            "batch32200-32300 speedup and saved\n",
            "batch32300-32400 speedup and saved\n",
            "batch32400-32500 speedup and saved\n",
            "batch32500-32600 speedup and saved\n",
            "batch32600-32700 speedup and saved\n",
            "batch32700-32800 speedup and saved\n",
            "batch32800-32900 speedup and saved\n",
            "batch32900-33000 speedup and saved\n",
            "batch33000-33100 speedup and saved\n",
            "batch33100-33200 speedup and saved\n",
            "batch33200-33300 speedup and saved\n",
            "batch33300-33400 speedup and saved\n",
            "batch33400-33500 speedup and saved\n",
            "batch33500-33600 speedup and saved\n",
            "batch33600-33700 speedup and saved\n",
            "batch33700-33800 speedup and saved\n",
            "batch33800-33900 speedup and saved\n",
            "batch33900-34000 speedup and saved\n",
            "batch34000-34100 speedup and saved\n",
            "batch34100-34200 speedup and saved\n",
            "batch34200-34300 speedup and saved\n",
            "batch34300-34400 speedup and saved\n",
            "batch34400-34500 speedup and saved\n",
            "batch34500-34600 speedup and saved\n",
            "batch34600-34700 speedup and saved\n",
            "batch34700-34800 speedup and saved\n",
            "batch34800-34900 speedup and saved\n",
            "batch34900-35000 speedup and saved\n",
            "batch35000-35100 speedup and saved\n",
            "batch35100-35200 speedup and saved\n",
            "batch35200-35300 speedup and saved\n",
            "batch35300-35400 speedup and saved\n",
            "batch35400-35500 speedup and saved\n",
            "batch35500-35600 speedup and saved\n",
            "batch35600-35700 speedup and saved\n",
            "batch35700-35800 speedup and saved\n",
            "batch35800-35900 speedup and saved\n",
            "batch35900-36000 speedup and saved\n",
            "batch36000-36100 speedup and saved\n",
            "batch36100-36200 speedup and saved\n",
            "batch36200-36300 speedup and saved\n",
            "batch36300-36400 speedup and saved\n",
            "batch36400-36500 speedup and saved\n",
            "batch36500-36600 speedup and saved\n",
            "batch36600-36700 speedup and saved\n",
            "batch36700-36800 speedup and saved\n",
            "batch36800-36900 speedup and saved\n",
            "batch36900-37000 speedup and saved\n",
            "batch37000-37100 speedup and saved\n",
            "batch37100-37200 speedup and saved\n",
            "batch37200-37300 speedup and saved\n",
            "batch37300-37400 speedup and saved\n",
            "batch37400-37500 speedup and saved\n",
            "batch37500-37600 speedup and saved\n",
            "batch37600-37700 speedup and saved\n",
            "batch37700-37800 speedup and saved\n",
            "batch37800-37900 speedup and saved\n",
            "batch37900-38000 speedup and saved\n",
            "batch38000-38100 speedup and saved\n",
            "batch38100-38122 speedup and saved\n",
            "training set: (72031, 300, 150)\n",
            "evaluation set: (3792, 300, 150)\n",
            "testing set: skes_joints_test_shape\n",
            "testing set sample after speed variation\n",
            "Split dataset success\n",
            "-----------------------\n"
          ]
        }
      ],
      "source": [
        "# For CNN-based model without view adaptation module\n",
        "base_path2 = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition/data/ntu'\n",
        "import os\n",
        "\n",
        "# 更改当前工作目录\n",
        "os.chdir(base_path2)\n",
        "\n",
        "# 运行Python脚本:change the test dataset to various to test models's motion-speed robustness\n",
        "!python seq_transformation.py --speed_train og_train --vali_sampling og_vali --various_test 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import os.path as osp\n",
        "\n",
        "# 假设 save_path 和 file_name 是你保存文件时使用的路径和文件名\n",
        "file_name = 'NTU_CV.h5'\n",
        "save_path = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition/data/ntu/transformed_data'\n",
        "file_path = osp.join(save_path, file_name)\n",
        "\n",
        "# 打开 HDF5 文件\n",
        "with h5py.File(file_path, 'r') as h5file:\n",
        "    # 读取 'test_x' 数据集\n",
        "    test_dataset = h5file['test_x']\n",
        "\n",
        "    # 打印数据集的形状\n",
        "    print(f\"Shape of 'test_x': {test_dataset.shape}\")\n",
        "\n",
        "    # 读取前几个样本进行验证\n",
        "    num_samples_to_check = 1\n",
        "    samples = test_dataset[:num_samples_to_check]\n",
        "\n",
        "    # 打印样本数据\n",
        "    for i, sample in enumerate(samples):\n",
        "        print(f\"Sample {i}:\")\n",
        "        print(sample)\n",
        "        # 如果需要，可以添加更多的验证逻辑，比如检查特定值或统计信息\n",
        "\n",
        "    # 读取 'test_y' 数据集（如果需要验证标签）\n",
        "    test_labels = h5file['test_y'][:num_samples_to_check]\n",
        "    print(f\"Test labels for first {num_samples_to_check} samples:\")\n",
        "    print(test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhi8AQjJng7Y",
        "outputId": "128b9ea8-6fe4-4b47-fa44-250bf94a2825"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of 'test_x': (38122, 300, 150)\n",
            "Sample 0:\n",
            "[[0.2181153 0.1725972 3.785547  ... 0.        0.        0.       ]\n",
            " [0.2182214 0.1738454 3.790635  ... 0.        0.        0.       ]\n",
            " [0.2186839 0.173486  3.788989  ... 0.        0.        0.       ]\n",
            " ...\n",
            " [0.        0.        0.        ... 0.        0.        0.       ]\n",
            " [0.        0.        0.        ... 0.        0.        0.       ]\n",
            " [0.        0.        0.        ... 0.        0.        0.       ]]\n",
            "Test labels for first 1 samples:\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition'\n",
        "# 更改当前工作目录\n",
        "import os\n",
        "os.chdir(base_path)\n",
        "# test the cnn model trained on original dataset's performance on twice faster testing set\n",
        "!python va-cnn.py --model baseline --aug 1 --train 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip8OYuCmSDmo",
        "outputId": "b5aab8a3-25e0-4916-84b6-c98b7dd46fae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100% 97.8M/97.8M [00:01<00:00, 72.9MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "Train on 75823 samples, validate on 3792 samples\n",
            "checkpoint1:./results/VA-CNN/NTU/baseline/1_best.pth\n",
            "checkpoint:./results/VA-CNN/NTU/baseline/1_best.pth\n",
            "Model Accuracy:1.64\n",
            "[1.64]\n",
            "ave: 1.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition'\n",
        "# 更改当前工作目录\n",
        "import os\n",
        "os.chdir(base_path)\n",
        "# test the cnn model trained on original dataset's performance on twice faster testing set\n",
        "!python va-cnn.py --model VA --aug 1 --train 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKjncSZymhI2",
        "outputId": "31e157e4-81de-44a4-d155-a8c87dc112a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 124MB/s] \n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "Train on 75823 samples, validate on 3792 samples\n",
            "checkpoint1:./results/VA-CNN/NTU/VA/1_best.pth\n",
            "checkpoint:./results/VA-CNN/NTU/VA/1_best.pth\n",
            "Model Accuracy:8.30\n",
            "[8.3]\n",
            "ave: 8.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For CNN-based model without view adaptation module\n",
        "base_path2 = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition/data/ntu'\n",
        "import os\n",
        "\n",
        "# 更改当前工作目录\n",
        "os.chdir(base_path2)\n",
        "\n",
        "# 运行Python脚本:change the test dataset to various to test models's motion-speed robustness\n",
        "!python seq_transformation.py --speed_train og_train --vali_sampling og_vali --various_test 1.25\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi0dUjl0nTgg",
        "outputId": "5b99f88b-7803-4156-a6ae-d73ca9cb817c",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (113945, 300, 150)\n",
            "-----------------------\n",
            "(38122, 300, 150)\n",
            "testing set sample before speed variation: \n",
            "training set: (72031, 300, 150)\n",
            "evaluation set: (3792, 300, 150)\n",
            "testing set: (38122, 300, 150)\n",
            "NTU_CV.h5 is opened.\n",
            "check the first speed up sample in txt\n",
            "batch0-1000 speedup and saved\n",
            "batch1000-2000 speedup and saved\n",
            "batch2000-3000 speedup and saved\n",
            "batch3000-4000 speedup and saved\n",
            "batch4000-5000 speedup and saved\n",
            "batch5000-6000 speedup and saved\n",
            "batch6000-7000 speedup and saved\n",
            "batch7000-8000 speedup and saved\n",
            "batch8000-9000 speedup and saved\n",
            "batch9000-10000 speedup and saved\n",
            "batch10000-11000 speedup and saved\n",
            "batch11000-12000 speedup and saved\n",
            "batch12000-13000 speedup and saved\n",
            "batch13000-14000 speedup and saved\n",
            "batch14000-15000 speedup and saved\n",
            "batch15000-16000 speedup and saved\n",
            "batch16000-17000 speedup and saved\n",
            "batch17000-18000 speedup and saved\n",
            "batch18000-19000 speedup and saved\n",
            "batch19000-20000 speedup and saved\n",
            "batch20000-21000 speedup and saved\n",
            "batch21000-22000 speedup and saved\n",
            "batch22000-23000 speedup and saved\n",
            "batch23000-24000 speedup and saved\n",
            "batch24000-25000 speedup and saved\n",
            "batch25000-26000 speedup and saved\n",
            "batch26000-27000 speedup and saved\n",
            "batch27000-28000 speedup and saved\n",
            "batch28000-29000 speedup and saved\n",
            "batch29000-30000 speedup and saved\n",
            "batch30000-31000 speedup and saved\n",
            "batch31000-32000 speedup and saved\n",
            "batch32000-33000 speedup and saved\n",
            "batch33000-34000 speedup and saved\n",
            "batch34000-35000 speedup and saved\n",
            "batch35000-36000 speedup and saved\n",
            "batch36000-37000 speedup and saved\n",
            "batch37000-38000 speedup and saved\n",
            "batch38000-38122 speedup and saved\n",
            "Split dataset success\n",
            "-----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VDq2PTo-J-Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition'\n",
        "# 更改当前工作目录\n",
        "import os\n",
        "os.chdir(base_path)\n",
        "print(os.getcwd())\n",
        "print('cnn trained on constant speed trainning set now test on 1.25 testing set')\n",
        "# test the cnn model trained on original dataset's performance on twice faster testing set\n",
        "!python va-cnn.py --model baseline --aug 1 --train 0\n",
        "print('va-cnn trained on constant speed trainning set now test on 1.25 testing set')\n",
        "# test the cnn model trained on original dataset's performance on twice faster testing set\n",
        "!python va-cnn.py --model VA --aug 1 --train 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njQR0BwhYwCk",
        "outputId": "10b5e867-1f4a-44b1-c978-76e6e60448a4",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition\n",
            "cnn trained on constant speed trainning set now test on 1.25 testing set\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 200MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "Train on 75823 samples, validate on 3792 samples\n",
            "checkpoint1:./results/VA-CNN/NTU/baseline/1_best.pth\n",
            "checkpoint:./results/VA-CNN/NTU/baseline/1_best.pth\n",
            "Model Accuracy:1.67\n",
            "[1.67]\n",
            "ave: 1.67\n",
            "va-cnn trained on constant speed trainning set now test on 1.25 testing set\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 196MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "Train on 75823 samples, validate on 3792 samples\n",
            "checkpoint1:./results/VA-CNN/NTU/VA/1_best.pth\n",
            "checkpoint:./results/VA-CNN/NTU/VA/1_best.pth\n",
            "Model Accuracy:9.15\n",
            "[9.15]\n",
            "ave: 9.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For CNN-based model without view adaptation module\n",
        "base_path2 = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition/data/ntu'\n",
        "import os\n",
        "\n",
        "# 更改当前工作目录\n",
        "os.chdir(base_path2)\n",
        "\n",
        "# 运行Python脚本:change the test dataset to various to test models's motion-speed robustness\n",
        "!python seq_transformation.py --speed_train og_train --vali_sampling og_vali --various_test 1.125"
      ],
      "metadata": {
        "id": "nsd8e9mmUNg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5415f40a-ad9a-4110-d2f1-bb8423587375"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (113945, 300, 150)\n",
            "-----------------------\n",
            "(38122, 300, 150)\n",
            "testing set sample before speed variation: \n",
            "training set: (72031, 300, 150)\n",
            "evaluation set: (3792, 300, 150)\n",
            "testing set: (38122, 300, 150)\n",
            "NTU_CV.h5 is opened.\n",
            "check the first speed up sample in txt\n",
            "batch0-1000 speedup and saved\n",
            "batch1000-2000 speedup and saved\n",
            "batch2000-3000 speedup and saved\n",
            "batch3000-4000 speedup and saved\n",
            "batch4000-5000 speedup and saved\n",
            "batch5000-6000 speedup and saved\n",
            "batch6000-7000 speedup and saved\n",
            "batch7000-8000 speedup and saved\n",
            "batch8000-9000 speedup and saved\n",
            "batch9000-10000 speedup and saved\n",
            "batch10000-11000 speedup and saved\n",
            "batch11000-12000 speedup and saved\n",
            "batch12000-13000 speedup and saved\n",
            "batch13000-14000 speedup and saved\n",
            "batch14000-15000 speedup and saved\n",
            "batch15000-16000 speedup and saved\n",
            "batch16000-17000 speedup and saved\n",
            "batch17000-18000 speedup and saved\n",
            "batch18000-19000 speedup and saved\n",
            "batch19000-20000 speedup and saved\n",
            "batch20000-21000 speedup and saved\n",
            "batch21000-22000 speedup and saved\n",
            "batch22000-23000 speedup and saved\n",
            "batch23000-24000 speedup and saved\n",
            "batch24000-25000 speedup and saved\n",
            "batch25000-26000 speedup and saved\n",
            "batch26000-27000 speedup and saved\n",
            "batch27000-28000 speedup and saved\n",
            "batch28000-29000 speedup and saved\n",
            "batch29000-30000 speedup and saved\n",
            "batch30000-31000 speedup and saved\n",
            "batch31000-32000 speedup and saved\n",
            "batch32000-33000 speedup and saved\n",
            "batch33000-34000 speedup and saved\n",
            "batch34000-35000 speedup and saved\n",
            "batch35000-36000 speedup and saved\n",
            "batch36000-37000 speedup and saved\n",
            "batch37000-38000 speedup and saved\n",
            "batch38000-38122 speedup and saved\n",
            "Split dataset success\n",
            "-----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_path = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition'\n",
        "# 更改当前工作目录\n",
        "\n",
        "os.chdir(base_path)\n",
        "print('cnn trained on constant speed trainning set now test on 1.125 testing set')\n",
        "# test the cnn model trained on original dataset's performance on twice faster testing set\n",
        "!python va-cnn.py --model baseline --aug 1 --train 0\n",
        "print('va-cnn trained on constant speed trainning set now test on 1.125 testing set')\n",
        "# test the cnn model trained on original dataset's performance on twice faster testing set\n",
        "!python va-cnn.py --model VA --aug 1 --train 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA0vzT38eqE3",
        "outputId": "4cdeb375-06f1-4b3a-b61b-c9b3786d3dcb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn trained on constant speed trainning set now test on 1.125 testing set\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "Train on 75823 samples, validate on 3792 samples\n",
            "checkpoint1:./results/VA-CNN/NTU/baseline/1_best.pth\n",
            "checkpoint:./results/VA-CNN/NTU/baseline/1_best.pth\n",
            "Model Accuracy:1.67\n",
            "[1.67]\n",
            "ave: 1.67\n",
            "va-cnn trained on constant speed trainning set now test on 1.125 testing set\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "Train on 75823 samples, validate on 3792 samples\n",
            "checkpoint1:./results/VA-CNN/NTU/VA/1_best.pth\n",
            "checkpoint:./results/VA-CNN/NTU/VA/1_best.pth\n",
            "Model Accuracy:9.24\n",
            "[9.24]\n",
            "ave: 9.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For CNN-based model without view adaptation module\n",
        "base_path2 = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition/data/ntu'\n",
        "import os\n",
        "\n",
        "# 更改当前工作目录\n",
        "os.chdir(base_path2)\n",
        "\n",
        "# 运行Python脚本:change the test dataset to various to test models's motion-speed robustness\n",
        "!python seq_transformation.py --speed_train og_train --vali_sampling og_vali --various_test 1.0625"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd__Qa7d92ic",
        "outputId": "5642a8b5-930d-48a6-8afe-5f3cfeb28522"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (113945, 300, 150)\n",
            "-----------------------\n",
            "(38122, 300, 150)\n",
            "testing set sample before speed variation: \n",
            "training set: (72031, 300, 150)\n",
            "evaluation set: (3792, 300, 150)\n",
            "testing set: (38122, 300, 150)\n",
            "NTU_CV.h5 is opened.\n",
            "check the first speed up sample in txt\n",
            "batch0-1000 speedup and saved\n",
            "batch1000-2000 speedup and saved\n",
            "batch2000-3000 speedup and saved\n",
            "batch3000-4000 speedup and saved\n",
            "batch4000-5000 speedup and saved\n",
            "batch5000-6000 speedup and saved\n",
            "batch6000-7000 speedup and saved\n",
            "batch7000-8000 speedup and saved\n",
            "batch8000-9000 speedup and saved\n",
            "batch9000-10000 speedup and saved\n",
            "batch10000-11000 speedup and saved\n",
            "batch11000-12000 speedup and saved\n",
            "batch12000-13000 speedup and saved\n",
            "batch13000-14000 speedup and saved\n",
            "batch14000-15000 speedup and saved\n",
            "batch15000-16000 speedup and saved\n",
            "batch16000-17000 speedup and saved\n",
            "batch17000-18000 speedup and saved\n",
            "batch18000-19000 speedup and saved\n",
            "batch19000-20000 speedup and saved\n",
            "batch20000-21000 speedup and saved\n",
            "batch21000-22000 speedup and saved\n",
            "batch22000-23000 speedup and saved\n",
            "batch23000-24000 speedup and saved\n",
            "batch24000-25000 speedup and saved\n",
            "batch25000-26000 speedup and saved\n",
            "batch26000-27000 speedup and saved\n",
            "batch27000-28000 speedup and saved\n",
            "batch28000-29000 speedup and saved\n",
            "batch29000-30000 speedup and saved\n",
            "batch30000-31000 speedup and saved\n",
            "batch31000-32000 speedup and saved\n",
            "batch32000-33000 speedup and saved\n",
            "batch33000-34000 speedup and saved\n",
            "batch34000-35000 speedup and saved\n",
            "batch35000-36000 speedup and saved\n",
            "batch36000-37000 speedup and saved\n",
            "batch37000-38000 speedup and saved\n",
            "batch38000-38122 speedup and saved\n",
            "Split dataset success\n",
            "-----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_path = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition'\n",
        "# 更改当前工作目录\n",
        "\n",
        "os.chdir(base_path)\n",
        "print('cnn trained on constant speed trainning set now test on 1.0625 testing set')\n",
        "# test the cnn model trained on original dataset's performance on twice faster testing set\n",
        "!python va-cnn.py --model baseline --aug 1 --train 0\n",
        "print('va-cnn trained on constant speed trainning set now test on 1.0625 testing set')\n",
        "# test the cnn model trained on original dataset's performance on twice faster testing set\n",
        "!python va-cnn.py --model VA --aug 1 --train 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poNB8dMqBwns",
        "outputId": "28f72b2d-77fb-4ea8-9aa1-509dc9ac0687"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn trained on constant speed trainning set now test on 1.0625 testing set\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "Train on 75823 samples, validate on 3792 samples\n",
            "checkpoint1:./results/VA-CNN/NTU/baseline/1_best.pth\n",
            "checkpoint:./results/VA-CNN/NTU/baseline/1_best.pth\n",
            "Model Accuracy:1.63\n",
            "[1.63]\n",
            "ave: 1.63\n",
            "va-cnn trained on constant speed trainning set now test on 1.0625 testing set\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "Train on 75823 samples, validate on 3792 samples\n",
            "checkpoint1:./results/VA-CNN/NTU/VA/1_best.pth\n",
            "checkpoint:./results/VA-CNN/NTU/VA/1_best.pth\n",
            "Model Accuracy:9.41\n",
            "[9.41]\n",
            "ave: 9.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For CNN-based model without view adaptation module\n",
        "base_path2 = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition/data/ntu'\n",
        "import os\n",
        "\n",
        "# 更改当前工作目录\n",
        "os.chdir(base_path2)\n",
        "\n",
        "# 运行Python脚本:change the test dataset to various to test models's motion-speed robustness\n",
        "!python seq_transformation.py --speed_train og_train --vali_sampling og_vali --various_test 1.03125"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IXCAf2jeNBKI",
        "outputId": "582ea058-8bad-4b09-92ff-06a1625efd30"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (113945, 300, 150)\n",
            "-----------------------\n",
            "(38122, 300, 150)\n",
            "testing set sample before speed variation: \n",
            "training set: (72031, 300, 150)\n",
            "evaluation set: (3792, 300, 150)\n",
            "testing set: (38122, 300, 150)\n",
            "NTU_CV.h5 is opened.\n",
            "check the first speed up sample in txt\n",
            "batch0-1000 speedup and saved\n",
            "batch1000-2000 speedup and saved\n",
            "batch2000-3000 speedup and saved\n",
            "batch3000-4000 speedup and saved\n",
            "batch4000-5000 speedup and saved\n",
            "batch5000-6000 speedup and saved\n",
            "batch6000-7000 speedup and saved\n",
            "batch7000-8000 speedup and saved\n",
            "batch8000-9000 speedup and saved\n",
            "batch9000-10000 speedup and saved\n",
            "batch10000-11000 speedup and saved\n",
            "batch11000-12000 speedup and saved\n",
            "batch12000-13000 speedup and saved\n",
            "batch13000-14000 speedup and saved\n",
            "batch14000-15000 speedup and saved\n",
            "batch15000-16000 speedup and saved\n",
            "batch16000-17000 speedup and saved\n",
            "batch17000-18000 speedup and saved\n",
            "batch18000-19000 speedup and saved\n",
            "batch19000-20000 speedup and saved\n",
            "batch20000-21000 speedup and saved\n",
            "batch21000-22000 speedup and saved\n",
            "batch22000-23000 speedup and saved\n",
            "batch23000-24000 speedup and saved\n",
            "batch24000-25000 speedup and saved\n",
            "batch25000-26000 speedup and saved\n",
            "batch26000-27000 speedup and saved\n",
            "batch27000-28000 speedup and saved\n",
            "batch28000-29000 speedup and saved\n",
            "batch29000-30000 speedup and saved\n",
            "batch30000-31000 speedup and saved\n",
            "batch31000-32000 speedup and saved\n",
            "batch32000-33000 speedup and saved\n",
            "batch33000-34000 speedup and saved\n",
            "batch34000-35000 speedup and saved\n",
            "batch35000-36000 speedup and saved\n",
            "batch36000-37000 speedup and saved\n",
            "batch37000-38000 speedup and saved\n",
            "batch38000-38122 speedup and saved\n",
            "Split dataset success\n",
            "-----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_path = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition'\n",
        "# 更改当前工作目录\n",
        "\n",
        "os.chdir(base_path)\n",
        "print('cnn trained on constant speed trainning set now test on 1.03125 testing set')\n",
        "# test the cnn model trained on original dataset's performance on twice faster testing set\n",
        "!python va-cnn.py --model baseline --aug 1 --train 0\n",
        "print('va-cnn trained on constant speed trainning set now test on 1.03125 testing set')\n",
        "# test the cnn model trained on original dataset's performance on twice faster testing set\n",
        "!python va-cnn.py --model VA --aug 1 --train 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlwqqkjUNFVj",
        "outputId": "af7bdc09-a69d-4bf6-847b-24afc9297869"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn trained on constant speed trainning set now test on 1.03125 testing set\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 228MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "Train on 75823 samples, validate on 3792 samples\n",
            "checkpoint1:./results/VA-CNN/NTU/baseline/1_best.pth\n",
            "checkpoint:./results/VA-CNN/NTU/baseline/1_best.pth\n",
            "Model Accuracy:1.68\n",
            "[1.68]\n",
            "ave: 1.68\n",
            "va-cnn trained on constant speed trainning set now test on 1.03125 testing set\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 201MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "Train on 75823 samples, validate on 3792 samples\n",
            "checkpoint1:./results/VA-CNN/NTU/VA/1_best.pth\n",
            "checkpoint:./results/VA-CNN/NTU/VA/1_best.pth\n",
            "Model Accuracy:9.47\n",
            "[9.47]\n",
            "ave: 9.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For CNN-based model without view adaptation module\n",
        "base_path2 = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition/data/ntu'\n",
        "import os\n",
        "\n",
        "# 更改当前工作目录\n",
        "os.chdir(base_path2)\n",
        "\n",
        "# 运行Python脚本:change the test dataset to various to test models's motion-speed robustness\n",
        "!python seq_transformation.py --speed_train og_train --vali_sampling og_vali --various_test 1.015625"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7MO89ynQPL3W",
        "outputId": "2861a4fb-d276-46aa-c87b-3b834f9a767a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (113945, 300, 150)\n",
            "-----------------------\n",
            "(38122, 300, 150)\n",
            "testing set sample before speed variation: \n",
            "training set: (72031, 300, 150)\n",
            "evaluation set: (3792, 300, 150)\n",
            "testing set: (38122, 300, 150)\n",
            "NTU_CV.h5 is opened.\n",
            "check the first speed up sample in txt\n",
            "batch0-1000 speedup and saved\n",
            "batch1000-2000 speedup and saved\n",
            "batch2000-3000 speedup and saved\n",
            "batch3000-4000 speedup and saved\n",
            "batch4000-5000 speedup and saved\n",
            "batch5000-6000 speedup and saved\n",
            "batch6000-7000 speedup and saved\n",
            "batch7000-8000 speedup and saved\n",
            "batch8000-9000 speedup and saved\n",
            "batch9000-10000 speedup and saved\n",
            "batch10000-11000 speedup and saved\n",
            "batch11000-12000 speedup and saved\n",
            "batch12000-13000 speedup and saved\n",
            "batch13000-14000 speedup and saved\n",
            "batch14000-15000 speedup and saved\n",
            "batch15000-16000 speedup and saved\n",
            "batch16000-17000 speedup and saved\n",
            "batch17000-18000 speedup and saved\n",
            "batch18000-19000 speedup and saved\n",
            "batch19000-20000 speedup and saved\n",
            "batch20000-21000 speedup and saved\n",
            "batch21000-22000 speedup and saved\n",
            "batch22000-23000 speedup and saved\n",
            "batch23000-24000 speedup and saved\n",
            "batch24000-25000 speedup and saved\n",
            "batch25000-26000 speedup and saved\n",
            "batch26000-27000 speedup and saved\n",
            "batch27000-28000 speedup and saved\n",
            "batch28000-29000 speedup and saved\n",
            "batch29000-30000 speedup and saved\n",
            "batch30000-31000 speedup and saved\n",
            "batch31000-32000 speedup and saved\n",
            "batch32000-33000 speedup and saved\n",
            "batch33000-34000 speedup and saved\n",
            "batch34000-35000 speedup and saved\n",
            "batch35000-36000 speedup and saved\n",
            "batch36000-37000 speedup and saved\n",
            "batch37000-38000 speedup and saved\n",
            "batch38000-38122 speedup and saved\n",
            "Split dataset success\n",
            "-----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_path = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition'\n",
        "# 更改当前工作目录\n",
        "\n",
        "os.chdir(base_path)\n",
        "print('cnn trained on constant speed trainning set now test on 1.03125 testing set')\n",
        "# test the cnn model trained on original dataset's performance on twice faster testing set\n",
        "!python va-cnn.py --model baseline --aug 1 --train 0\n",
        "print('va-cnn trained on constant speed trainning set now test on 1.03125 testing set')\n",
        "# test the cnn model trained on original dataset's performance on twice faster testing set\n",
        "!python va-cnn.py --model VA --aug 1 --train 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4nXwg5pPQGS",
        "outputId": "f26fd10e-2ac1-424f-a9e1-4acca4cebdd8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn trained on constant speed trainning set now test on 1.03125 testing set\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "Train on 75823 samples, validate on 3792 samples\n",
            "checkpoint1:./results/VA-CNN/NTU/baseline/1_best.pth\n",
            "checkpoint:./results/VA-CNN/NTU/baseline/1_best.pth\n",
            "Model Accuracy:1.67\n",
            "[1.67]\n",
            "ave: 1.67\n",
            "va-cnn trained on constant speed trainning set now test on 1.03125 testing set\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "Train on 75823 samples, validate on 3792 samples\n",
            "checkpoint1:./results/VA-CNN/NTU/VA/1_best.pth\n",
            "checkpoint:./results/VA-CNN/NTU/VA/1_best.pth\n",
            "Model Accuracy:9.59\n",
            "[9.59]\n",
            "ave: 9.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For CNN-based model without view adaptation module\n",
        "base_path2 = '/content/drive/Othercomputers/我的笔记本电脑/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition/data/ntu'\n",
        "import os\n",
        "\n",
        "# 更改当前工作目录\n",
        "os.chdir(base_path2)\n",
        "\n",
        "# 运行Python脚本:change the test dataset to various to test models's motion-speed robustness\n",
        "!python seq_transformation.py --speed_train og_train --vali_sampling og_vali --various_test 1.015625"
      ],
      "metadata": {
        "id": "IqdGO1NbTCQs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}